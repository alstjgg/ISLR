# 2.1 Statistical Learning?

Input Variables: X_1, X_2, ...
Output Variables: Y
=>통계적으로 관련성 파악
=>수식으로 표현 => Y = f(X) + e (i.e. 종속변수가 독립변수에 의해 표현된다)

Statistical Learning => f 함수를 예측하는 것

## 2.1.1 Why Estimate f?

#### 예측
- 대부분 X는 주어지지만 Y는 주어지지 않음
- Y 햇 = f햇(X) 을 통해 예측 (오차 평균이 0)

f햇은 f와 같지 않고 오차가 있다 => Reducible Error (f햇을 개선하면 오차 줄일 수 있음)
f(X)으로 Y햇을 예측한다 => Irreducible Error

Example: 집단 A의 Input이 X, Output이 Y고, 집단 B의 Input이 X햇, Output이 Y햇이면, X로 Y를 예측하는 것은 f, X햇으로 Y햇을 예측하는 것은 f햇이다.
이때, f햇을 개선하여 f처럼 오차를 줄이는 것은 가능하나, A집단과 B집단 자체가 다르기 때문에 (Y햇과 Y) 줄일 수 없는 오차는 잔존한다.

Eq 2.3 : E(Y-Y햇)^2 = E[f(X) + e - f햇(X)]^2 = [f(X) - f햇(X)]^2 + var(e)

#### 추측
예측하지 못하고 추측이 필요한 경우
- 어느 예측이 응답과 관련있는지
- 응답과 각 에측사이의 관계
- Y와 예측이 선형으로 나타낼 수 있는지

결론: 모델에 따라 예측, 추측 모두 필요할 수도 있다.

## 2.1.2 How Do We Estimate f?

1. Parametric Methods
  - 함수 형태에 대한 가정을 한다
  - 모델을 선택한 후 training data로 학습시켜서 매개변수를 찾는다
2. Non-Parametric Methods
  - 함수 형태에 대해 명시적인 가정을 하지 않는다
  - 너무 대강하지 않되, 예측치와 최대한 가깝게 지나는 f를 예측한다

## 2.1.3 The Trade-Off between Prediction Accuracy and Model Interpretability

모델의 해석가능성과 정확도 반비례한다

Example

Low Interpretability                                      High Interpretability
Deep Learning - SVM - Bagging, Boosting - Generalized Addictive Models Trees - Least Squares - Subset Selection Lasso
High Flexibility                                          Low Flexibility

High Interpretability 선택 이유
- 추측하는 경우

High Flexibility  선택 이유
- (복잡한) 예측하는 경우

## 2.1.4 Supvervised Vs Unsupervised Learning

Supervised Learning
- x_i에 대한 y_i가 주어진다
- GAM, boosting, SVM..

Unsupervised Learning
- x_i에 관련된 y_i가 없다
- 예측할 응답이 없다
- Clustering..

# 2.2 Assessing Model Accuracy

한 방법이 모든 데이터 셋에 적용되지 않기 때문에 여러 접근방법 시도

## 2.2.1 Measuring the Quality of Fit

예측이 실제로 잘 맞는 지 파악하는 방법

Model - Measurement
Regression - MSE(mean squared error)
- 작을수록 예측값과 실제값이 유사
- 예측값과 실제값 차의 제곱을 평균한 것
- 단점: train MSE가 가장 작다고 test MSE가 가장 작은 것은 아니다
- 너무 rough 하거나 wiggly 하지 않도록 규제가 필요함 (flexibility level 조절)
- test data 가 없기 때문에 training MSE를 계산하는 것은 쉽지만 test MSE 계산은 어려움
- 후속 개념: Cross-Validation in Chapter 5

## 2.2.2 The Bias-Variance Trade-Off







  
  
  
